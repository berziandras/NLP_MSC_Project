{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.691649353055761\n",
      "salty fries <-> hamburgers 0.6938489675521851\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed_spotify_millsongdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "1 0.8741539109971664\n",
      "2 0.9077283360126182\n",
      "3 0.7225779463026504\n",
      "4 0.7266883289949204\n",
      "5 0.9055352443833733\n",
      "6 0.9083962969083499\n",
      "7 0.9382528797038523\n",
      "8 0.9632340730512098\n",
      "9 0.6794751068443333\n",
      "10 0.9426772320498384\n",
      "11 0.845761447325602\n",
      "12 0.9429962974152005\n",
      "13 0.9203727952377316\n",
      "14 0.9373624654496512\n",
      "15 0.9212590159549555\n",
      "16 0.8347543260574359\n",
      "17 0.9405269278838501\n",
      "18 0.9225343742380688\n",
      "19 0.03189922254959234\n",
      "20 0.8809336667231678\n",
      "21 0.8817357716108796\n",
      "22 0.9164792943863521\n",
      "23 0.8010742579263227\n",
      "24 0.8884983674745428\n",
      "25 0.8989822759736188\n",
      "26 0.8737817537966464\n",
      "27 0.8873298187669784\n",
      "28 0.9364792291537561\n",
      "29 0.8863246418035725\n",
      "30 0.8657917127861641\n",
      "31 0.8375883018016127\n",
      "32 0.895293745775481\n",
      "33 0.9147718673587081\n",
      "34 0.9573112546240591\n",
      "35 0.8671510472878259\n",
      "36 0.7888472543066696\n",
      "37 0.9043541914086477\n",
      "38 0.9204496887957481\n",
      "39 0.9104315517687396\n",
      "40 0.9274915009811573\n",
      "41 0.9283288884197088\n",
      "42 0.8977033881985543\n",
      "43 0.8454688712976639\n",
      "44 0.8972104103607607\n",
      "45 0.6060093035009074\n",
      "46 0.9427450207296558\n",
      "47 0.890008817313227\n",
      "48 0.7866155687490354\n",
      "49 0.8453158231048657\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    doc1 = nlp(df['cleaned_text'][0])\n",
    "    doc2 = nlp(df['cleaned_text'][i])\n",
    "\n",
    "    # Similarity of two documents\n",
    "    print(i, doc1.similarity(doc2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
